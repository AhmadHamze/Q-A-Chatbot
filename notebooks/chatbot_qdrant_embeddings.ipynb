{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c48cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install sentence_transformers\n",
    "!pip install scikit-learn\n",
    "!pip install faiss-gpu-cu12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d675f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from google.colab import userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0d185",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"ruslanmv/ai-medical-chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325187d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"train\"][0][\"Description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1115f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = [(entry[\"Patient\"], entry[\"Doctor\"]) for entry in ds[\"train\"]]\n",
    "questions, answers = zip(*qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b0a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model with GPU\n",
    "embed_model = SentenceTransformer(\"neuml/pubmedbert-base-embeddings\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43a69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "\n",
    "QDRANT_HOST = userdata.get(\"QDRANT_HOST\")\n",
    "QDRANT_API_KEY = userdata.get(\"QDRANT_API_KEY\")\n",
    "COLLECTION_NAME = \"ruslanmv-ai-medical-chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Initialize Qdrant Client ----\n",
    "client = QdrantClient(\n",
    "    url=QDRANT_HOST,\n",
    "    api_key=QDRANT_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Create Collection ----\n",
    "if not client.collection_exists(collection_name=COLLECTION_NAME):\n",
    "    print(\"Creating collection\", COLLECTION_NAME)\n",
    "    client.create_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=768,  # Depends on your embedding model, neuml/pubmedbert-base-embeddings is a 768 dimensional dense vector space\n",
    "            distance=models.Distance.COSINE\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"Collection already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fcb465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process embeddings in batches\n",
    "batch_size = 64  # Larger batch size for GPU\n",
    "question_embeddings = embed_model.encode(\n",
    "    questions,\n",
    "    batch_size=batch_size,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "# Upload to Qdrant\n",
    "# client.upload_collection(\n",
    "#     collection_name=COLLECTION_NAME,\n",
    "#     vectors=question_embeddings,\n",
    "#     payloads=[{\"answer\": answer} for answer in answers],\n",
    "#     ids=[str(i) for i in range(len(questions))],\n",
    "#     batch_size=batch_size\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
