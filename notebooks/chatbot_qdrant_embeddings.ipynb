{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c48cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install sentence_transformers\n",
    "!pip install scikit-learn\n",
    "!pip install qdrant-client sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d675f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from google.colab import userdata\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from tqdm import tqdm\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0d185",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"ruslanmv/ai-medical-chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325187d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"train\"][0][\"Description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1115f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = [(entry[\"Patient\"], entry[\"Doctor\"]) for entry in ds[\"train\"]]\n",
    "questions, answers = zip(*qa_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b0a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model with GPU\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43a69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Config ----\n",
    "QDRANT_HOST = userdata.get(\"QDRANT_HOST\")\n",
    "QDRANT_API_KEY = userdata.get(\"QDRANT_API_KEY\")\n",
    "COLLECTION_NAME = \"ruslanmv-ai-medical-chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Initialize Qdrant Client ----\n",
    "client = QdrantClient(\n",
    "    url=QDRANT_HOST,\n",
    "    api_key=QDRANT_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Create Collection ----\n",
    "if not client.collection_exists(collection_name=COLLECTION_NAME):\n",
    "    print(\"Creating collection\", COLLECTION_NAME)\n",
    "    client.create_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=384,  # Depends on your embedding model, all-MiniLM-L6-v2 is a 384 dimensional dense vector space\n",
    "            distance=models.Distance.COSINE\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(\"Collection already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fcb465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process embeddings in batches\n",
    "batch_size = 64  # Larger batch size for GPU\n",
    "question_embeddings = embed_model.encode(\n",
    "    questions,\n",
    "    batch_size=batch_size,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True,\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fd5725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to Qdrant\n",
    "\n",
    "\"\"\"\n",
    "'answer' is needed in the payload, otherwise, finding the context will be harder and costly.\n",
    "It is important to have an id that can be identified later, having uuids randomly is not good.\n",
    "\"\"\"\n",
    "\n",
    "for i in tqdm(range(0, len(questions), batch_size)):\n",
    "    batch_questions = questions[i : i + batch_size]\n",
    "    batch_answers = answers[i : i + batch_size]\n",
    "    batch_vectors = question_embeddings[i : i + batch_size]\n",
    "\n",
    "    points_batch = [\n",
    "        models.PointStruct(\n",
    "            id=i+j+1,\n",
    "            vector=batch_vectors[j],\n",
    "            payload={\"question\": batch_questions[j], \"answer\": batch_answers[j]}\n",
    "            )\n",
    "        for j in range(len(batch_questions))\n",
    "    ]\n",
    "    client.upsert(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        points=points_batch,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c015fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nearest = client.query_points(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query=embed_model.encode(\"Hi doctor, I fell on the stairs and I hurt my anckle very bad, what should I do?\"),\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "for point in nearest.points:\n",
    "    print(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef84e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query: str) -> str:\n",
    "    nearest = client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query=embed_model.encode(query),\n",
    "        limit=3\n",
    "    )\n",
    "    return \"\\n\\n\".join([f\"Patient: {question}\\nDoctor: {answer}\" for question, answer in [(point.payload[\"question\"], point.payload[\"answer\"]) for point in nearest.points]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
